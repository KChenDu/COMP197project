{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Oxford-IIIT Pet Dataset\n",
    "***\n",
    "## Part 1\n",
    "\n",
    "This part is only a demo of Oxford-IIIT Pet Dataset using Torchvision API. We may use it for development.\n",
    "\n",
    "Download the dataset and display the number of datapoints and classes:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869f81a424004007"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:23.933111Z",
     "start_time": "2024-03-03T21:12:21.638252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 3680\n",
      "Number of classes:\t    37\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import OxfordIIITPet\n",
    "from random import randint\n",
    "\n",
    "\n",
    "data_category = OxfordIIITPet('.', download=True)\n",
    "length = len(data_category)\n",
    "print(\"Number of datapoints:\", length)\n",
    "classes = data_category.classes\n",
    "print(\"Number of classes:\\t   \", len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select a random sample and display its label:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6098ff4bceb3f22b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Staffordshire Bull Terrier !\n"
     ]
    }
   ],
   "source": [
    "image, label = data_category[randint(0, length - 1)]\n",
    "print(\"This is a\", classes[label], '!')\n",
    "image.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:28.230067Z",
     "start_time": "2024-03-03T21:12:23.934735Z"
    }
   },
   "id": "3426332beba7ea8c",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above approach is for classification task. Now let's see the dataset for segmentation task:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a82acaffb3edff4a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_segmentation = OxfordIIITPet('.', target_types='segmentation', download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:28.307575Z",
     "start_time": "2024-03-03T21:12:28.231072Z"
    }
   },
   "id": "9305a458d1fa662e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image, label = data_segmentation[randint(0, length - 1)]\n",
    "image.show()\n",
    "label.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:35.172279Z",
     "start_time": "2024-03-03T21:12:28.308646Z"
    }
   },
   "id": "e60c71d91865aa17",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2\n",
    "This part is for loading the dataset using H5ImageLoader class. We probably will not use this class for development.\n",
    "\n",
    "Here is how we load the dataset:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d3f75a08262fb19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from loader import H5ImageLoader\n",
    "from PIL.Image import fromarray\n",
    "\n",
    "\n",
    "# Instantiate a loader to iterate over the dataset 1 by 1 (batch size 1)\n",
    "loader = H5ImageLoader('oxford-iiit-pet/images_train.h5', 1, 'oxford-iiit-pet/labels_train.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:35.239319Z",
     "start_time": "2024-03-03T21:12:35.174880Z"
    }
   },
   "id": "92eb15fe573549b1",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's iterate over the dataset and display the first image and its label:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e2127f32a014c87"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look the lengths of the list \"images\" and \"labels\"! They must be equal to the batch size: 1 , 1\n"
     ]
    }
   ],
   "source": [
    "for images, labels in loader:\n",
    "    print('Look the lengths of the list \"images\" and \"labels\"! They must be equal to the batch size:', len(images), ',', len(labels))\n",
    "    # Finally, show the image and its label\n",
    "    image = fromarray(images[0])\n",
    "    image.show()\n",
    "    label = fromarray(labels[0])\n",
    "    label.show()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T21:12:42.464257Z",
     "start_time": "2024-03-03T21:12:35.240324Z"
    }
   },
   "id": "55526e9bde133bc7",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "[click to see professor's `.py` demo](demo.py)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45251b82f7c4548a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
