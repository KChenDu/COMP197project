{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869f81a424004007",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Oxford-IIIT Pet Dataset\n",
    "***\n",
    "## Part 1\n",
    "\n",
    "This part is only a demo of Oxford-IIIT Pet Dataset using Torchvision API. We may not use it in development.\n",
    "\n",
    "Download the dataset and display the number of datapoints and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:08:47.689548Z",
     "start_time": "2024-03-09T23:08:45.883837Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import OxfordIIITPet\n",
    "from random import randint\n",
    "\n",
    "\n",
    "data_category = OxfordIIITPet('.', download=True)\n",
    "length = len(data_category)\n",
    "print(\"Number of datapoints:\", length)\n",
    "classes = data_category.classes\n",
    "print(\"Number of classes:\\t   \", len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098ff4bceb3f22b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Select a random sample and display its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426332beba7ea8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:08:51.432432Z",
     "start_time": "2024-03-09T23:08:47.691554Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image, label = data_category[randint(0, length - 1)]\n",
    "print(\"This is a\", classes[label], '!')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82acaffb3edff4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above approach is for classification task. Now let's see the dataset for segmentation task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305a458d1fa662e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:08:51.510657Z",
     "start_time": "2024-03-09T23:08:51.433446Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_segmentation = OxfordIIITPet('.', target_types='segmentation', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c71d91865aa17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:08:58.368594Z",
     "start_time": "2024-03-09T23:08:51.511662Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image, label = data_segmentation[randint(0, length - 1)]\n",
    "image.show()\n",
    "label.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f75a08262fb19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2\n",
    "This part is for loading the dataset using `H5ImageLoader` class from professor. We probably will not use this class for development.\n",
    "\n",
    "Here is how we load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb15fe573549b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:08:58.407243Z",
     "start_time": "2024-03-09T23:08:58.369601Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from loader import H5ImageLoader\n",
    "from PIL.Image import fromarray\n",
    "\n",
    "\n",
    "# Instantiate a loader to iterate over the dataset 1 by 1 (batch size 1)\n",
    "loader = H5ImageLoader('oxford-iiit-pet/images_train.h5', 1, 'oxford-iiit-pet/labels_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2127f32a014c87",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's iterate over the dataset and display the first image and its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55526e9bde133bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T23:09:05.213359Z",
     "start_time": "2024-03-09T23:08:58.409272Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for images, labels in loader:\n",
    "    print('Look the lengths of the list \"images\" and \"labels\"! They must be equal to the batch size:', len(images), ',', len(labels))\n",
    "    # Finally, show the image and its label\n",
    "    image = fromarray(images[0])\n",
    "    image.show()\n",
    "    label = fromarray(labels[0])\n",
    "    label.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa4894143def31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[click to see professor's `.py` demo](demo.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91421f6975b7c1a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3\n",
    "This part shows how to do the same thing using our `SimpleOxfordPetDataset` class. This class is a wrapper for the `OxfordIIITPet` class in `segmentation_models_pytorch` library, and it gives pre-processed images and labels. Very probably we will use this class in development.\n",
    "\n",
    "Download the dataset and display the number of datapoints and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94221c6bdd92f78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:28:29.761770Z",
     "start_time": "2024-03-10T12:28:17.483883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import SimpleOxfordPetDataset\n",
    "from random import randint\n",
    "\n",
    "\n",
    "root = \"oxford-iiit-pet\"\n",
    "SimpleOxfordPetDataset.download(root)\n",
    "train_dataset = SimpleOxfordPetDataset(root, \"train\")\n",
    "length = len(train_dataset)\n",
    "print(\"Number of datapoints:\", length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090e3b1d30e3390",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that this dataset is made up of torch.Tensor objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4a3db6898d206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:28:29.779150Z",
     "start_time": "2024-03-10T12:28:29.762916Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image, label = train_dataset[randint(0, length - 1)]\n",
    "\n",
    "print(\"image:\\n\\t路 type:\", type(image), \"\\n\\t路 shape:\", image.shape)\n",
    "print(\"label:\\n\\t路 type:\", type(label), \"\\n\\t路 shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e94db99c9a627",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Select a random sample and display its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c7503edfe4f0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:28:29.949179Z",
     "start_time": "2024-03-10T12:28:29.780172Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image, label = image.numpy(), label.numpy()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image.transpose(1, 2, 0)) # for visualization we have to transpose back to HWC\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(label.squeeze())  # for visualization we have to remove 3rd dimension of mask\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
